{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/datasets/geo_data_0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Abrimos y revisamos los datos:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_0 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/datasets/geo_data_0.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m df_1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/datasets/geo_data_1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m df_2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/datasets/geo_data_2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/datasets/geo_data_0.csv'"
     ]
    }
   ],
   "source": [
    "#Abrimos y revisamos los datos:\n",
    "df_0 = pd.read_csv('/datasets/geo_data_0.csv')\n",
    "df_1 = pd.read_csv('/datasets/geo_data_1.csv')\n",
    "df_2 = pd.read_csv('/datasets/geo_data_2.csv')\n",
    "print('Base de datos muestra')\n",
    "print(df_0.head())\n",
    "print()\n",
    "print('Informacion variables')\n",
    "print(df_0.info())\n",
    "print()\n",
    "print('tamaño df')\n",
    "print(df_0.shape)\n",
    "print()\n",
    "\n",
    "def print_falt_values(region_num, df_num):   \n",
    "    print(f\"Valores faltantes de {region_num}:\\n{df_num.isna().sum()}\")\n",
    "    print(\"-\" * 50)\n",
    "print_falt_values(\"Región 0\", df_0)\n",
    "print_falt_values(\"Región 1\", df_1)\n",
    "print_falt_values(\"Región 2\", df_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos en los Df parecen estar completos, organizados y del tipo correcto, se procederá a separar las variables independientes de las dependientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a separar features y target (recordar que id no aporta información para el modelo)\n",
    "def separe_features_target(df_num):   \n",
    "    target=df_num['product']\n",
    "    features = df_num.drop(['product', 'id'], axis = 1)\n",
    "    return features, target\n",
    "\n",
    "x_0, y_0 = separe_features_target(df_0)\n",
    "x_1, y_1 = separe_features_target(df_1)\n",
    "x_2, y_2 = separe_features_target(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño conjunto Entrenamiento Región 0: (75000, 3)\n",
      "Tamaño conjunto Validación Región 0: (12500, 3)\n",
      "Tamaño conjunto Prueba Región 0: (12500, 3)\n",
      "--------------------------------------------------\n",
      "Tamaño conjunto Entrenamiento Región 1: (75000, 3)\n",
      "Tamaño conjunto Validación Región 1: (12500, 3)\n",
      "Tamaño conjunto Prueba Región 1: (12500, 3)\n",
      "--------------------------------------------------\n",
      "Tamaño conjunto Entrenamiento Región 2: (75000, 3)\n",
      "Tamaño conjunto Validación Región 2: (12500, 3)\n",
      "Tamaño conjunto Prueba Región 2: (12500, 3)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Dividimos los conjuntos de entrenamiento y validación\n",
    "def divide_data(x, y, test_size = .25, valid_size = .5, random_state = 1):\n",
    "    x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size = test_size, random_state = random_state)\n",
    "    x_valid, x_test, y_valid, y_test = train_test_split(x_temp, y_temp, test_size = valid_size, random_state = random_state)\n",
    "    return x_train, x_valid, x_test, y_train, y_valid, y_test\n",
    "\n",
    "x_0_train, x_0_valid, x_0_test, y_0_train, y_0_valid, y_0_test = divide_data(x_0, y_0)\n",
    "x_1_train, x_1_valid, x_1_test, y_1_train, y_1_valid, y_1_test = divide_data(x_1, y_1)\n",
    "x_2_train, x_2_valid, x_2_test, y_2_train, y_2_valid, y_2_test = divide_data(x_2, y_2)\n",
    "\n",
    "#Confirmamos los tamaños de los \n",
    "def print_shape(region, x_train, x_valid, x_test):\n",
    "    print(f\"Tamaño conjunto Entrenamiento {region}: {x_train.shape}\")\n",
    "    print(f\"Tamaño conjunto Validación {region}: {x_valid.shape}\")\n",
    "    print(f\"Tamaño conjunto Prueba {region}: {x_test.shape}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print_shape(\"Región 0\", x_0_train, x_0_valid, x_0_test)\n",
    "print_shape(\"Región 1\", x_1_train, x_1_valid, x_1_test)\n",
    "print_shape(\"Región 2\", x_2_train, x_2_valid, x_2_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE de la región 0: 37.78214551400566\n",
      "\n",
      "Media de predicciones de la región 0: 92.39\n"
     ]
    }
   ],
   "source": [
    "#Entrenamos el modelo para la región 0\n",
    "model_0 = LinearRegression()\n",
    "model_0.fit(x_0_train, y_0_train)\n",
    "pred_0 = model_0.predict(x_0_valid)\n",
    "rmse_0 = mean_squared_error(y_0_valid, pred_0, squared=False)\n",
    "#Respuestas región 0\n",
    "print(f'RMSE de la región 0: {rmse_0}')     \n",
    "print()\n",
    "print(f\"Media de predicciones de la región 0: {pred_0.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Región 0 RMSE: 37.78\n",
      "Región 0 Media predicha: 92.39\n",
      "--------------------------------------------------\n",
      "Región 1 RMSE: 0.89\n",
      "Región 1 Media predicha: 68.97\n",
      "--------------------------------------------------\n",
      "Región 2 RMSE: 40.02\n",
      "Región 2 Media predicha: 94.94\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Definimos la Función\n",
    "def eval_reg(x_train, y_train, x_valid, y_valid):\n",
    "    model = LinearRegression()\n",
    "    model.fit(x_train, y_train)\n",
    "    pred = model.predict(x_valid)\n",
    "    rmse = mean_squared_error(y_valid, pred, squared=False)\n",
    "    mean_pred = pred.mean()\n",
    "    return model, pred, rmse, mean_pred\n",
    "\n",
    "#Usamos la función con las 3 regiones \n",
    "def print_eval_reg(region, x_train, y_train, x_valid, y_valid):\n",
    "    model, pred, rmse, mean_pred = eval_reg(x_train, y_train, x_valid, y_valid)\n",
    "    print(f\"{region} RMSE: {rmse:.2f}\")\n",
    "    print(f\"{region} Media predicha: {mean_pred:.2f}\")\n",
    "    print(\"-\" * 50)\n",
    "    return model, pred, rmse, mean_pred\n",
    "\n",
    "model_0, pred_0, rmse_0, mean_pred_0 = print_eval_reg(\"Región 0\", x_0_train, y_0_train, x_0_valid, y_0_valid)\n",
    "model_1, pred_1, rmse_1, mean_pred_1 = print_eval_reg(\"Región 1\", x_1_train, y_1_train, x_1_valid, y_1_valid)\n",
    "model_2, pred_2, rmse_2, mean_pred_2 = print_eval_reg(\"Región 2\", x_2_train, y_2_train, x_2_valid, y_2_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-En la Región 0, en promedio, el modelo se equivoca en 37,780 barriles por pozo y  predice un promedio de 92,390 barriles por pozo.\n",
    "\n",
    "-En la Región 1, en promedio, el modelo se equivoca en 890 barriles por pozo y  predice un promedio de 68,970 barriles por pozo.\n",
    "\n",
    "-En la Región 2, en promedio, el modelo se equivoca en 40,020 barriles por pozo y  predice un promedio de 94,940 barriles por pozo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La producción media requerida por pozo para cubrir costos debe ser de 111.11 miles de barriles\n",
      "\n",
      "--------------------------------------------------\n",
      "Producción promedio Región 0: 92.39 miles de barriles\n",
      "--------------------------------------------------\n",
      "Producción promedio Región 1: 68.97 miles de barriles\n",
      "--------------------------------------------------\n",
      "Producción promedio Región 2: 94.94 miles de barriles\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Nos preparamos para el calculo de ganancias.\n",
    "#Almacenamos valores para calculo\n",
    "inv_tot=100000000\n",
    "num_wells=200\n",
    "income_unit=4500\n",
    "#Calculamos la producción en miles de barriles requerida por pozo\n",
    "def print_production_avrg(inv_tot, num_wells, income_unit, medias_por_region):\n",
    "    product_req = inv_tot/num_wells/income_unit\n",
    "    print(f\"La producción media requerida por pozo para cubrir costos debe ser de {product_req:.2f} miles de barriles\\n\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for region, media in medias_por_region.items():\n",
    "        print(f\"Producción promedio {region}: {media:.2f} miles de barriles\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "medias_por_region = {\n",
    "    \"Región 0\": mean_pred_0,\n",
    "    \"Región 1\": mean_pred_1,\n",
    "    \"Región 2\": mean_pred_2}\n",
    "\n",
    "print_production_avrg(inv_tot, num_wells, income_unit, medias_por_region)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Se requiere que en promedio cada pozo produzca 111.11 mil barriles por pozo; sin embargo, las predicciones medias de las tres regiones están debajo de ese objetivo y por lo tanto, ninguna garantiza rentabilidad solo con el promedio.\n",
    "\n",
    "-Necesitamos seleccionar los 200 mejores pozos con mayor poduccion predicha y ver si logran superar el objetivo de 111.11 mil barriles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de Región 0:\n",
      "Producción promedio (200 mejores pozos): 144.61 miles de barriles\n",
      "Ingreso estimado: 130,151,186.30 USD\n",
      "Ganancia estimada: 30,151,186.30 USD\n",
      "--------------------------------------------------\n",
      "Resultados de Región 1:\n",
      "Producción promedio (200 mejores pozos): 137.95 miles de barriles\n",
      "Ingreso estimado: 124,150,866.97 USD\n",
      "Ganancia estimada: 24,150,866.97 USD\n",
      "--------------------------------------------------\n",
      "Resultados de Región 2:\n",
      "Producción promedio (200 mejores pozos): 138.52 miles de barriles\n",
      "Ingreso estimado: 124,667,627.26 USD\n",
      "Ganancia estimada: 24,667,627.26 USD\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Calculemos la ganancia esperada de los 200 pozos con mayor produccion estimada\n",
    "#Comenzaremos haciendo una función que prediga la produccion de barriles de \n",
    "#petroleo y el beneficio total esperado del modelo para los 200 pozos más productivos.\n",
    "def calculate_profit(model, x_test, y_test, sample_size=200, income_per_unit=4500):\n",
    "    predictions = model.predict(x_test)\n",
    "    top_prod_well = predictions.argsort()[-sample_size:]\n",
    "    selected_well = y_test.iloc[top_prod_well]\n",
    "    total_income = selected_well.sum()*income_per_unit\n",
    "    return total_income, selected_well, predictions[top_prod_well]\n",
    "\n",
    "#Resultados por region \n",
    "def print_results_region(region, selected_well, total_income, inv_tot):\n",
    "    print(f\"Resultados de {region}:\")\n",
    "    print(f\"Producción promedio (200 mejores pozos): {selected_well.mean():.2f} miles de barriles\")\n",
    "    print(f\"Ingreso estimado: {total_income:,.2f} USD\")\n",
    "    print(f\"Ganancia estimada: {(total_income - inv_tot):,.2f} USD\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "#Calculamos los ingresos estimados por el modelo de los 200 mejores pozos por región.\n",
    "total_income_0, selected_well_0, pred_0_selected = calculate_profit(model_0, x_0_test, y_0_test)\n",
    "total_income_1, selected_well_1, pred_1_selected = calculate_profit(model_1, x_1_test, y_1_test)\n",
    "total_income_2, selected_well_2, pred_2_selected = calculate_profit(model_2, x_2_test, y_2_test)\n",
    "\n",
    "print_results_region(\"Región 0\", selected_well_0, total_income_0, inv_tot)\n",
    "print_results_region(\"Región 1\", selected_well_1, total_income_1, inv_tot)\n",
    "print_results_region(\"Región 2\", selected_well_2, total_income_2, inv_tot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ganancia que se obtendría si se utilizaran la media de producción de los 200 pozos principales por región incrementaría con respecto al anterior calculo que solo calculaba la produccion media de la región; por lo que bajo ese supuesto, todas las regiones serían rentables al tener una producción estimada mayor de 111.11 miles de barriles, siendo la opción más viable la Región 0, pues la ganancia estimada sería de 30,151,186.30 USD.\n",
    "\n",
    "\n",
    "Sin embargo este resultado asume que al hacer labores de exploración y explotación petrolera, OilyGiant accederá a los 200 pozos principales, lo cual es poco probable; por lo que se prosigue con el método bootstrapping a buscar la probabilidad de que las ganancias sean positivas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcularemos riesgos y ganancias para cada región\n",
    "#Utilizamos la técnica de remuestreo bootstrapping y hallamos las ganancias\n",
    "def bootstrap_profit(model, x_test, y_test, n_iterations=1000, \n",
    "                     sample_size=500, num_wells=200, income_unit=4500, \n",
    "                     inv_tot=100000000, random_state=1):\n",
    "\n",
    "    state = np.random.RandomState(random_state)\n",
    "    profits = []\n",
    "#Creamos el bucle para seleccionar 1000 muestras aleatorias de 500 pozos cada una\n",
    "    for i in range(n_iterations):\n",
    "        sample_index = state.choice(x_test.index, size=sample_size, replace=True)\n",
    "        x_subsample = x_test.loc[sample_index]\n",
    "        y_subsample = y_test.loc[sample_index]\n",
    "#Predecimos la produccion de los pozos en las muestras aleatorias con el modelo\n",
    "        predictions = model.predict(x_subsample)\n",
    "#Elejimos los 200 pozos con mayor produccion esperada\n",
    "        top_prod_idx = predictions.argsort()[-num_wells:]\n",
    "        selected_real = y_subsample.iloc[top_prod_idx]\n",
    "#Calculamos ingreso y lo agreganos a la lista profits[]\n",
    "        income = selected_real.sum() * income_unit\n",
    "        profits.append(income)\n",
    "#Obtenemos los ingresos medios con profits.mean() y el intervalo del 95%\n",
    "    profits = pd.Series(profits)\n",
    "    mean_income = profits.mean()\n",
    "    interval = profits.quantile([0.025, 0.975])\n",
    "    risk = (profits < inv_tot).mean()\n",
    "\n",
    "    return mean_income, (interval.loc[0.025], interval.loc[0.975]), risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_0, interval_0, risk_0 = bootstrap_profit(model_0, x_0_test, y_0_test)\n",
    "mean_1, interval_1, risk_1 = bootstrap_profit(model_1, x_1_test, y_1_test)\n",
    "mean_2, interval_2, risk_2 = bootstrap_profit(model_2, x_2_test, y_2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados bootstrapping de Región 0\n",
      "Ingreso promedio: $104,210,543.30\n",
      "Intervalo del 95%: $98,889,725.66 - $109,632,920.17\n",
      "Riesgo de pérdida: 6.60%\n",
      "--------------------------------------------------\n",
      "Resultados bootstrapping de Región 1\n",
      "Ingreso promedio: $104,848,209.26\n",
      "Intervalo del 95%: $101,037,160.17 - $108,882,160.77\n",
      "Riesgo de pérdida: 0.90%\n",
      "--------------------------------------------------\n",
      "Resultados bootstrapping de Región 2\n",
      "Ingreso promedio: $104,155,614.08\n",
      "Intervalo del 95%: $98,931,008.39 - $109,633,409.31\n",
      "Riesgo de pérdida: 5.70%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def print_bootstrap_results(region_num, mean_income, interval, risk):\n",
    "    print(f\"Resultados bootstrapping de {region_num}\")\n",
    "    print(f\"Ingreso promedio: ${mean_income:,.2f}\")\n",
    "    print(f\"Intervalo del 95%: ${interval[0]:,.2f} - ${interval[1]:,.2f}\")\n",
    "    print(f\"Riesgo de pérdida: {risk:.2%}\")\n",
    "    print(\"-\" * 50)\n",
    "print_bootstrap_results(\"Región 0\", mean_0, interval_0, risk_0)\n",
    "print_bootstrap_results(\"Región 1\", mean_1, interval_1, risk_1)\n",
    "print_bootstrap_results(\"Región 2\", mean_2, interval_2, risk_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior a elaborar el método bootstrapping, en donde se hicieron mil iteraciones de 500 muestras para calcular la probabilidad de acceder a los 200 pozos principales, se procedió a calcular el ingreso promedio esperado, el intervalo de confianza del 95% y los riesgos de pérdida.\n",
    "\n",
    "Bajo esta evaluación, obtenemos que la Región 1 es la más viable para el proyecto de extracción, pues reporta los ingresos promedio esperados más elevados: $104,848,209.26.\n",
    "\n",
    "Todos los valores del ingreso esperado dentro del intervalo del 95 % de confianza se encuentran por encima del valor de la inversión. Además, el riesgo de pérdida (la probabilidad de que la inversión sea mayor que el ingreso) es el más bajo, con solo un 0.9 % de probabilidad. Esto hace que la Región 1 sea la opción más viable para el proyecto de extracción.\n",
    "\n",
    "El cambio de decisión sobre la región más viable (de la Región 0 a la Región 1) se debe a que, en la primera evaluación, se trabajó bajo el supuesto de que la empresa OilyGiant lograría identificar y explotar exactamente los 200 pozos más productivos.\n",
    "\n",
    "Sin embargo, encontrar los pozos más rentables es una cuestión de probabilidad, influida por diversos factores geológicos. Por ello, la Región 1 se vuelve la opción más viable, ya que presenta una mayor probabilidad de contener pozos de alta producción, lo que se traduce en mayores ganancias esperadas y el menor riesgo de pérdida."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
